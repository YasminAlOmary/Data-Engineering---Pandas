{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9991597-b30d-4897-b78a-435bb5d52696",
   "metadata": {},
   "source": [
    "## Pandas CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71535fa9-8353-4020-a7f7-2d7cc4bf1f46",
   "metadata": {},
   "source": [
    "## Read CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d99cc651-c075-49bf-85c8-c80a83b949b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee ID First Name Last Name Department     Position  Salary\n",
      "0          101       John       Doe  Marketing      Manager   50000\n",
      "1          102       Jane     Smith      Sales    Associate   35000\n",
      "2          103    Michael   Johnson    Finance      Analyst   45000\n",
      "3          104      Emily  Williams         HR  Coordinator   40000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read csv file\n",
    "df = pd.read_csv('data2.csv', header = 0)\n",
    "\n",
    "print(df)\n",
    "\n",
    "#Here, header = 0 sets the first row as the header of the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7503e04-5412-4c59-ab74-caaaefe80041",
   "metadata": {},
   "source": [
    "## read_csv() With Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c28d409-933c-4482-a569-de03ed2138ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         col1         col2   col3\n",
      "102 Jane    Smith       Sales    Associate  35000\n",
      "103 Michael Johnson   Finance      Analyst  45000\n",
      "104 Emily   Williams       HR  Coordinator  40000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read csv file with some arguments\n",
    "df = pd.read_csv('data2.csv', header = None, names = ['col1', 'col2', 'col3'], skiprows = 2)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365460ca-0871-4cbf-9a67-37fa7e43a7f1",
   "metadata": {},
   "source": [
    "## Pandas Read Text File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc224f-ef8d-4ec4-922c-e7fec8dbbf76",
   "metadata": {},
   "source": [
    "### Read Text Using read_fwf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e6018-1769-4c9a-a808-e86fd061a018",
   "metadata": {},
   "source": [
    "The acronym fwf in the read_fwf() function in Pandas stands for fixed-width lines, and it is used to load DataFrames from files such as text files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c9f2c-199b-46e8-8aaf-9eaee643fc6e",
   "metadata": {},
   "source": [
    "## read_fwf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9ec7f0bc-95bf-4d2b-ac9e-a1d2c5101e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Height\n",
      "0   John   25      70\n",
      "1  Alice   28      65\n",
      "2    Bob   30      80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the fixed-width file\n",
    "df = pd.read_fwf('data.txt', colspecs=[(0, 5), (6, 10), (11, 15)], names = ['Name', 'Age', 'Height'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010cb1c7-6564-4452-a8c9-45be6402ac55",
   "metadata": {},
   "source": [
    "###  Read Text Using read_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "00db0194-5265-43dc-a95e-879d6a58dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Height\n",
      "0   John   25     170\n",
      "1  Alice   28     165\n",
      "2    Bob   30     180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the file using read_table()\n",
    "df = pd.read_table(\"data.txt\", sep=\"\\\\s+\", names=['Name', 'Age', 'Height'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4502136-9855-4127-a67f-b843b8587fb8",
   "metadata": {},
   "source": [
    "## Read Text Using read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c136f75e-005c-428c-9170-9ecd35f07755",
   "metadata": {},
   "source": [
    "## read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6d71b66e-48a4-4428-9a30-9241308143a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age  Height\n",
      "0   John   25     170\n",
      "1  Alice   28     165\n",
      "2    Bob   30     180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the file using read_table()\n",
    "df = pd.read_csv(\"data.txt\", sep=\"\\\\s+\", header = None, names=['Name', 'Age', 'Height'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084a46c-9ccf-4437-b9b1-06faf2b3b07b",
   "metadata": {},
   "source": [
    "## Write to CSV Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b0c237e-8918-46eb-8085-0168c90a6eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dictionary\n",
    "data = {'Name': ['John', 'Alice', 'Bob'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'London', 'Paris']}\n",
    "\n",
    "# create a dataframe from the dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# write dataframe to csv file\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b4342e-adf5-4749-b63d-de2d7f4959a2",
   "metadata": {},
   "source": [
    "## to_csv() With Arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b38f77-5536-4c7b-86f1-cf5318306a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "data = {'Name': ['Tom', 'Nick', 'John', 'Tom'],\n",
    "        'Age': [20, 21, 19, 18],\n",
    "        'City': ['New York', 'London', 'Paris', 'Berlin']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# write to csv file\n",
    "df.to_csv('output.csv', sep = ';', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568128f5-cb4c-4cda-83ab-4ef95630f86f",
   "metadata": {},
   "source": [
    "## Pandas Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3a11187-f6a3-4f6f-9e73-c9216d754c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees:\n",
      "  EmployeeID         Name DeptID\n",
      "0       E001     John Doe   D001\n",
      "1       E002   Jane Smith   D003\n",
      "2       E003  Peter Brown   D001\n",
      "3       E004  Tom Johnson   D002\n",
      "4       E005   Rita Patel   D003\n",
      "\n",
      "Departments:\n",
      "  DeptID DeptName\n",
      "0   D001    Sales\n",
      "1   D002       HR\n",
      "2   D003    Admin\n",
      "\n",
      "Merged DataFrame:\n",
      "  EmployeeID         Name DeptID DeptName\n",
      "0       E001     John Doe   D001    Sales\n",
      "1       E003  Peter Brown   D001    Sales\n",
      "2       E002   Jane Smith   D003    Admin\n",
      "3       E005   Rita Patel   D003    Admin\n",
      "4       E004  Tom Johnson   D002       HR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D003'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# merge dataframes employees and departments\n",
    "merged_df = pd.merge(employees, departments)\n",
    "\n",
    "# display DataFrames\n",
    "print(\"Employees:\")\n",
    "print(employees)\n",
    "print()\n",
    "print(\"Departments:\")\n",
    "print(departments)\n",
    "print()\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf93194-e375-4013-90b4-c013db280669",
   "metadata": {},
   "source": [
    "## Merge DataFrames Based on Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63aa6fe7-2d53-49da-87e2-297f0444e4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID1 DeptID2 DeptName\n",
      "0       E001     John Doe    D001    D001    Sales\n",
      "1       E003  Peter Brown    D001    D001    Sales\n",
      "2       E004  Tom Johnson    D002    D002       HR\n",
      "3       E002   Jane Smith    D003    D003    Admin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID1': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID2': ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# merge the dataframes\n",
    "df_merge = pd.merge(employees, departments, left_on='DeptID1', right_on = 'DeptID2', sort = True)\n",
    "\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc9cb2-8758-4568-a392-63d320b887e2",
   "metadata": {},
   "source": [
    "## Types of Join Operations In merge()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e88207b-bcca-4cce-a7f4-44551bdff2d5",
   "metadata": {},
   "source": [
    "\n",
    "Left Join\n",
    "\n",
    "Right Join\n",
    "\n",
    "Outer Join\n",
    "\n",
    "Inner Join (Default)\n",
    "\n",
    "Cross Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6249d79b-73bd-466f-8710-87432a3b1a0d",
   "metadata": {},
   "source": [
    "## Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35db70be-0dcf-4e63-9c4a-76456f324500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID DeptName\n",
      "0       E001     John Doe   D001    Sales\n",
      "1       E003  Peter Brown   D001    Sales\n",
      "2       E004  Tom Johnson   D002       HR\n",
      "3       E002   Jane Smith   D003    Admin\n",
      "4       E005   Rita Patel   D006      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# left merge the dataframes\n",
    "df_merge = pd.merge(employees, departments, on = 'DeptID', how = 'left', sort = True)\n",
    "\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0e5bd-e26e-4b47-8389-95f354ae4bc7",
   "metadata": {},
   "source": [
    "## Right Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cab3e939-05f5-40b3-b6b2-4dee97609f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID   DeptName\n",
      "0       E001     John Doe   D001      Sales\n",
      "1       E003  Peter Brown   D001      Sales\n",
      "2       E004  Tom Johnson   D002         HR\n",
      "3       E002   Jane Smith   D003      Admin\n",
      "4        NaN          NaN   D004  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# right merge the dataframes\n",
    "df_merge = pd.merge(employees, departments, on = 'DeptID', how = 'right', sort = True)\n",
    "\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fbfa50-657f-4a18-97dd-7691fd39f1e2",
   "metadata": {},
   "source": [
    "## Inner Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d399fc34-4e64-4243-9635-582a96e7e6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID DeptName\n",
      "0       E001     John Doe   D001    Sales\n",
      "1       E003  Peter Brown   D001    Sales\n",
      "2       E004  Tom Johnson   D002       HR\n",
      "3       E002   Jane Smith   D003    Admin\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# inner merge the dataframes\n",
    "df_merge = pd.merge(employees, departments, on = 'DeptID', how = 'inner', sort = True)\n",
    "\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93368f5-dfb6-447a-8951-d7d57e5519f4",
   "metadata": {},
   "source": [
    "## Outer Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "47c38286-c4e0-41e7-bd5f-aeb28459da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID   DeptName\n",
      "0       E001     John Doe   D001      Sales\n",
      "1       E003  Peter Brown   D001      Sales\n",
      "2       E004  Tom Johnson   D002         HR\n",
      "3       E002   Jane Smith   D003      Admin\n",
      "4        NaN          NaN   D004  Marketing\n",
      "5       E005   Rita Patel   D006        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# outer merge the dataframes\n",
    "df_merge = pd.merge(employees, departments, on = 'DeptID', how = 'outer', sort = True)\n",
    "\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc04655-8f3a-45a5-93e0-d37b72c1b6d9",
   "metadata": {},
   "source": [
    "## Cross Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da65a71d-5c4c-45fc-9a6c-280be088b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID         Name DeptID_x DeptID_y   DeptName\n",
      "0        E001     John Doe     D001     D001      Sales\n",
      "1        E001     John Doe     D001     D002         HR\n",
      "2        E001     John Doe     D001     D003      Admin\n",
      "3        E001     John Doe     D001     D004  Marketing\n",
      "4        E002   Jane Smith     D003     D001      Sales\n",
      "5        E002   Jane Smith     D003     D002         HR\n",
      "6        E002   Jane Smith     D003     D003      Admin\n",
      "7        E002   Jane Smith     D003     D004  Marketing\n",
      "8        E003  Peter Brown     D001     D001      Sales\n",
      "9        E003  Peter Brown     D001     D002         HR\n",
      "10       E003  Peter Brown     D001     D003      Admin\n",
      "11       E003  Peter Brown     D001     D004  Marketing\n",
      "12       E004  Tom Johnson     D002     D001      Sales\n",
      "13       E004  Tom Johnson     D002     D002         HR\n",
      "14       E004  Tom Johnson     D002     D003      Admin\n",
      "15       E004  Tom Johnson     D002     D004  Marketing\n",
      "16       E005   Rita Patel     D006     D001      Sales\n",
      "17       E005   Rita Patel     D006     D002         HR\n",
      "18       E005   Rita Patel     D006     D003      Admin\n",
      "19       E005   Rita Patel     D006     D004  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID': ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name': ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# merge the dataframes\n",
    "df_merge = pd.merge(employees, departments, how = 'cross')\n",
    "\n",
    "print(df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64524692-f9d6-488e-979e-0590cf2461c8",
   "metadata": {},
   "source": [
    "## Join vs Merge vs Concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b45b4a-bb7b-4cb6-8fad-747b6e127834",
   "metadata": {},
   "source": [
    "## Pandas Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "61627825-71d3-4fb0-b2e3-e6b836d24969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 1:\n",
      "      A   B\n",
      "K0  A0  B0\n",
      "K1  A1  B1\n",
      "K2  A2  B2\n",
      "K3  A3  B3\n",
      "\n",
      "DataFrame 2:\n",
      "      C   D\n",
      "K0  C0  D0\n",
      "K1  C1  D1\n",
      "K2  C2  D2\n",
      "K3  C3  D3\n",
      "\n",
      "Joined DataFrame:\n",
      "      A   B   C   D\n",
      "K0  A0  B0  C0  D0\n",
      "K1  A1  B1  C1  D1\n",
      "K2  A2  B2  C2  D2\n",
      "K3  A3  B3  C3  D3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe 1\n",
    "data1 = {\n",
    "    'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "}\n",
    "df1 = pd.DataFrame(data1, index=['K0', 'K1', 'K2', 'K3'])\n",
    "\n",
    "# create dataframe 2\n",
    "data2 = {\n",
    "    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "    'D': ['D0', 'D1', 'D2', 'D3'],\n",
    "}\n",
    "df2 = pd.DataFrame(data2, index=['K0', 'K1', 'K2', 'K3'])\n",
    "\n",
    "# join dataframes\n",
    "df_join = df1.join(df2)\n",
    "\n",
    "# display DataFrames\n",
    "print(\"DataFrame 1:\\n\", df1)\n",
    "print(\"\\nDataFrame 2:\\n\", df2)\n",
    "print(\"\\nJoined DataFrame:\\n\", df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1632100-21a6-4d5c-9bff-c30c61a68ad6",
   "metadata": {},
   "source": [
    "## Join DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05d43ced-3443-4f40-9c3d-126cb9ee43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID DeptName_left DeptName_right\n",
      "0       E001     John Doe   D001        Sales1         Sales2\n",
      "1       E002   Jane Smith   D003        Admin1         Admin2\n",
      "2       E003  Peter Brown   D001        Sales1         Sales2\n",
      "3       E004  Tom Johnson   D002           HR1            HR2\n",
      "4       E005   Rita Patel   D006           N/A            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D006'],\n",
    "    'DeptName': ['Sales1', 'Admin1', 'Sales1', 'HR1', 'N/A']\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID' : ['D001', 'D002', 'D003', 'D004'],\n",
    "    'DeptName' : ['Sales2', 'HR2', 'Admin2', 'Marketing2']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# set DeptID as index for departments dataframe\n",
    "departments = departments.set_index('DeptID')\n",
    "\n",
    "# join the dataframes based on columns\n",
    "df_join = employees.join(departments, on = 'DeptID', lsuffix = '_left', rsuffix = '_right')\n",
    "\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728583e3-45dd-407d-a703-5d845cb6581a",
   "metadata": {},
   "source": [
    "## Types of Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7aa24d-6efb-497b-8c5d-7ea09c133f01",
   "metadata": {},
   "source": [
    "Left Join (Default)\n",
    "\n",
    "Right Join\n",
    "\n",
    "Outer Join\n",
    "\n",
    "Inner Join\n",
    "\n",
    "Cross Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848168b7-e3b5-477f-8d2a-55e88db043c5",
   "metadata": {},
   "source": [
    "## Left Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f2bc42a0-b89e-4846-864d-bb7ebad2f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID DeptName\n",
      "0       E001     John Doe   D001    Sales\n",
      "1       E002   Jane Smith   D003    Admin\n",
      "2       E003  Peter Brown   D001    Sales\n",
      "3       E004  Tom Johnson   D002       HR\n",
      "4       E005   Rita Patel   D005      NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D005'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003','D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# set DeptID as index for departments\n",
    "departments.set_index('DeptID',inplace=True)\n",
    "\n",
    "# left join\n",
    "df_join = employees.join(departments, on = 'DeptID', how = 'left')\n",
    "\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c678ff2-39df-42cc-991c-bee183c6f7c4",
   "metadata": {},
   "source": [
    "## Right Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "58651e97-78c4-44c8-a3f9-dd3e480c85b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID   DeptName\n",
      "0       E001     John Doe   D001      Sales\n",
      "1       E003  Peter Brown   D001      Sales\n",
      "2       E004  Tom Johnson   D002         HR\n",
      "3       E002   Jane Smith   D003      Admin\n",
      "4        NaN          NaN   D004  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D005'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003','D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# set DeptID as index for departments\n",
    "departments.set_index('DeptID', inplace=True)\n",
    "\n",
    "# right join\n",
    "df_join = employees.join(departments, on = 'DeptID', how = 'right')\n",
    "\n",
    "# reset index\n",
    "df_join.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63533389-4c60-475e-a5a9-d57962d5ab74",
   "metadata": {},
   "source": [
    "## Inner Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be9ad8df-7e90-4cf5-83f9-086df0b176d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID DeptName\n",
      "0       E001     John Doe   D001    Sales\n",
      "1       E003  Peter Brown   D001    Sales\n",
      "2       E002   Jane Smith   D003    Admin\n",
      "3       E004  Tom Johnson   D002       HR\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D005'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003','D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# set DeptID as index for departments\n",
    "departments.set_index('DeptID',inplace=True)\n",
    "\n",
    "# inner join\n",
    "df_join = employees.join(departments, on = 'DeptID', how = 'inner')\n",
    "\n",
    "# reset index\n",
    "df_join.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3b27d-6693-4642-abd0-c9acdb14d6de",
   "metadata": {},
   "source": [
    "## Outer Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "658f0185-2768-4bf9-990a-e4ce21f415fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EmployeeID         Name DeptID   DeptName\n",
      "0       E001     John Doe   D001      Sales\n",
      "1       E003  Peter Brown   D001      Sales\n",
      "2       E002   Jane Smith   D003      Admin\n",
      "3       E004  Tom Johnson   D002         HR\n",
      "4       E005   Rita Patel   D005        NaN\n",
      "5        NaN          NaN   D004  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D005'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003','D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# set DeptID as index for departments\n",
    "departments.set_index('DeptID',inplace=True)\n",
    "\n",
    "# outer join\n",
    "df_join = employees.join(departments, on = 'DeptID', how = 'outer')\n",
    "\n",
    "# reset index\n",
    "df_join.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f97c72-0cd5-412c-9ebc-1f1b27c590b2",
   "metadata": {},
   "source": [
    " ## Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "146188e8-887f-494a-a15c-a688b492b567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID         Name DeptID   DeptName\n",
      "0        E001     John Doe   D001      Sales\n",
      "1        E001     John Doe   D001         HR\n",
      "2        E001     John Doe   D001      Admin\n",
      "3        E001     John Doe   D001  Marketing\n",
      "4        E002   Jane Smith   D003      Sales\n",
      "5        E002   Jane Smith   D003         HR\n",
      "6        E002   Jane Smith   D003      Admin\n",
      "7        E002   Jane Smith   D003  Marketing\n",
      "8        E003  Peter Brown   D001      Sales\n",
      "9        E003  Peter Brown   D001         HR\n",
      "10       E003  Peter Brown   D001      Admin\n",
      "11       E003  Peter Brown   D001  Marketing\n",
      "12       E004  Tom Johnson   D002      Sales\n",
      "13       E004  Tom Johnson   D002         HR\n",
      "14       E004  Tom Johnson   D002      Admin\n",
      "15       E004  Tom Johnson   D002  Marketing\n",
      "16       E005   Rita Patel   D005      Sales\n",
      "17       E005   Rita Patel   D005         HR\n",
      "18       E005   Rita Patel   D005      Admin\n",
      "19       E005   Rita Patel   D005  Marketing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes from the dictionaries\n",
    "data1 = {\n",
    "    'EmployeeID' : ['E001', 'E002', 'E003', 'E004', 'E005'],\n",
    "    'Name' : ['John Doe', 'Jane Smith', 'Peter Brown', 'Tom Johnson', 'Rita Patel'],\n",
    "    'DeptID': ['D001', 'D003', 'D001', 'D002', 'D005'],\n",
    "}\n",
    "employees = pd.DataFrame(data1)\n",
    "\n",
    "data2 = {\n",
    "    'DeptID': ['D001', 'D002', 'D003','D004'],\n",
    "    'DeptName': ['Sales', 'HR', 'Admin', 'Marketing']\n",
    "}\n",
    "departments = pd.DataFrame(data2)\n",
    "\n",
    "# set DeptID as index for departments\n",
    "departments.set_index('DeptID',inplace=True)\n",
    "\n",
    "# cross join\n",
    "df_join = employees.join(departments, how = 'cross')\n",
    "\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2bcf4e-a8d0-4294-8589-f44d3ea0e23d",
   "metadata": {},
   "source": [
    "## Pandas Concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2e8871dc-5594-43ad-aceb-9d8accf10ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B\n",
      "0  A0  B0\n",
      "1  A1  B1\n",
      "2  A2  B2\n",
      "3  A3  B3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1'],\n",
    "                    'B': ['B0', 'B1']},\n",
    "                    index=[0, 1])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A2', 'A3'],\n",
    "                    'B': ['B2', 'B3']},\n",
    "                    index=[2, 3])\n",
    "\n",
    "# concatenate two dataframes\n",
    "result = pd.concat([df1, df2])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bedf659-8c85-455e-8605-1e8a8ce25358",
   "metadata": {},
   "source": [
    "## concat() With Arguments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c37bbc8b-8886-4cda-946e-d36552dc9bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ignore_index = True\n",
      "       Name  Age      City\n",
      "0     John   25  New York\n",
      "1    Alice   30     Paris\n",
      "2      Bob   35    London\n",
      "3    Emily   28    Berlin\n",
      "4  Michael   32     Tokyo\n",
      "5   Sophia   27    Sydney\n",
      "6     Rita   22     Delhi\n",
      "\n",
      "sort = True\n",
      "    Age      City     Name\n",
      "0   25  New York     John\n",
      "1   30     Paris    Alice\n",
      "2   35    London      Bob\n",
      "0   28    Berlin    Emily\n",
      "1   32     Tokyo  Michael\n",
      "2   27    Sydney   Sophia\n",
      "3   22     Delhi     Rita\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Alice', 'Bob'],\n",
    "                    'Age': [25, 30, 35],\n",
    "                    'City': ['New York', 'Paris', 'London']})\n",
    "\n",
    "df2 = pd.DataFrame({'Name': ['Emily', 'Michael', 'Sophia', 'Rita'],\n",
    "                    'Age': [28, 32, 27, 22],\n",
    "                    'City': ['Berlin', 'Tokyo', 'Sydney', 'Delhi']})\n",
    "\n",
    "# concatenate dataframes while ignoring index\n",
    "result_ignore_index = pd.concat([df1, df2], ignore_index = True)\n",
    "\n",
    "# concatenate dataframes and sort the result\n",
    "result_sort = pd.concat([df1, df2], sort = True)\n",
    "\n",
    "# display the concatenated results\n",
    "print('ignore_index = True\\n', result_ignore_index)\n",
    "print('\\nsort = True\\n', result_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc5f68c-719b-4942-bc6b-24bdc283b17f",
   "metadata": {},
   "source": [
    "## Concatenation Along Axis 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4b6186a2-847a-4ca8-8bde-4ae07af88b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name   Age      City     Name  Age    City\n",
      "0   John  25.0  New York    Emily   28  Berlin\n",
      "1  Alice  30.0     Paris  Michael   32   Tokyo\n",
      "2    Bob  35.0    London   Sophia   27  Sydney\n",
      "3    NaN   NaN       NaN     Rita   22   Delhi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Alice', 'Bob'],\n",
    "                    'Age': [25, 30, 35],\n",
    "                    'City': ['New York', 'Paris', 'London']})\n",
    "\n",
    "df2 = pd.DataFrame({'Name': ['Emily', 'Michael', 'Sophia', 'Rita'],\n",
    "                    'Age': [28, 32, 27, 22],\n",
    "                    'City': ['Berlin', 'Tokyo', 'Sydney', 'Delhi']})\n",
    "\n",
    "# concatenate dataframes along axis 1\n",
    "result = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d633d46-3462-47a5-8af8-8f758a11ad26",
   "metadata": {},
   "source": [
    "## Inner Join Vs Outer Join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f7091107-6819-4ca5-99c2-070ffd8db7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Join\n",
      "     Name   Age      City     Name  Age    City\n",
      "0   John  25.0  New York    Emily   28  Berlin\n",
      "1  Alice  30.0     Paris  Michael   32   Tokyo\n",
      "2    Bob  35.0    London   Sophia   27  Sydney\n",
      "3    NaN   NaN       NaN     Rita   22   Delhi\n",
      "\n",
      "Inner Join\n",
      "     Name  Age      City     Name  Age    City\n",
      "0   John   25  New York    Emily   28  Berlin\n",
      "1  Alice   30     Paris  Michael   32   Tokyo\n",
      "2    Bob   35    London   Sophia   27  Sydney\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Alice', 'Bob'],\n",
    "                    'Age': [25, 30, 35],\n",
    "                    'City': ['New York', 'Paris', 'London']})\n",
    "\n",
    "df2 = pd.DataFrame({'Name': ['Emily', 'Michael', 'Sophia', 'Rita'],\n",
    "                    'Age': [28, 32, 27, 22],\n",
    "                    'City': ['Berlin', 'Tokyo', 'Sydney', 'Delhi']})\n",
    "\n",
    "\n",
    "# concatenate dataframes with outer join\n",
    "result_outer = pd.concat([df1, df2], axis = 1)\n",
    "\n",
    "# concatenate dataframes with inner join\n",
    "result_inner = pd.concat([df1, df2], axis = 1, join = 'inner')\n",
    "\n",
    "# display the concatenated results\n",
    "print('Outer Join\\n', result_outer)\n",
    "print('\\nInner Join\\n', result_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5af6032-4c16-43c5-bff0-f8766b38a347",
   "metadata": {},
   "source": [
    "## Concatenation With Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "755e9539-c7c8-4a31-a240-5d33cc0b4c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Name  Age      City\n",
      "from_df1 0     John   25  New York\n",
      "         1    Alice   30     Paris\n",
      "         2      Bob   35    London\n",
      "from_df2 0    Emily   28    Berlin\n",
      "         1  Michael   32     Tokyo\n",
      "         2   Sophia   27    Sydney\n",
      "         3     Rita   22     Delhi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframes\n",
    "df1 = pd.DataFrame({'Name': ['John', 'Alice', 'Bob'],\n",
    "                    'Age': [25, 30, 35],\n",
    "                    'City': ['New York', 'Paris', 'London']})\n",
    "\n",
    "df2 = pd.DataFrame({'Name': ['Emily', 'Michael', 'Sophia', 'Rita'],\n",
    "                    'Age': [28, 32, 27, 22],\n",
    "                    'City': ['Berlin', 'Tokyo', 'Sydney', 'Delhi']})\n",
    "\n",
    "\n",
    "# concatenate dataframes while ignoring index\n",
    "result = pd.concat([df1, df2], keys = ['from_df1', 'from_df2'])\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a118d7-75ad-4859-9420-266cef4af35d",
   "metadata": {},
   "source": [
    "## Reading Excel File using Pandas in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33c484db-54db-40dc-8e17-c761136b06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Roll No.  English  Maths  Science\n",
      "0  0         1       19     13       17\n",
      "1  1         2       14     20       18\n",
      "2  2         3       15     18       19\n",
      "3  3         4       13     14       14\n",
      "4  4         5       17     16       20\n",
      "5  5         6       19     13       17\n",
      "6  6         7       14     20       18\n",
      "7  7         8       15     18       19\n",
      "8  8         9       13     14       14\n",
      "9  9        10       17     16       20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('data.xlsx')\n",
    "print(df)\n",
    "\n",
    "#pip install openpyxl for No module named 'openpyxl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8ddbc61c-1176-473f-9710-9fd1e2483384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0         1       19     13       17, 1         2       14     20       18, 2         3       15     18       19, 3         4       13     14       14, 4         5       17     16       20, 5         6       19     13       17, 6         7       14     20       18, 7         8       15     18       19, 8         9       13     14       14, 9        10       17     16       20, 0         1       2     2       2, 1         2       2     2       2, 2         3       2     2       2, 3         4       13     14       14, 4         5       17     16       20, 5         6       19     13       17, 6         7       14     20       18, 7         8       15     18       19, 8         9       13     14       14, 9        10       17     16       20]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "file = 'data.xlsx'\n",
    "sheet1 = pd.read_excel(file, \n",
    "                        sheet_name = 0, \n",
    "                        index_col = 0)\n",
    " \n",
    "sheet2 = pd.read_excel(file, \n",
    "                        sheet_name = 1, \n",
    "                        index_col = 0)\n",
    " \n",
    "# concatinating both the sheets\n",
    "newData = pd.concat([sheet1, sheet2])\n",
    "print(newData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d137bb43-3db7-482e-8335-62a8bbe4cefb",
   "metadata": {},
   "source": [
    "## Head() and Tail() methods in Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "77ea2060-1c93-4105-accb-b8274521398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0         1       19     13       17, 1         2       14     20       18, 2         3       15     18       19, 3         4       13     14       14, 4         5       17     16       20]\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [5         6       19     13       17, 6         7       14     20       18, 7         8       15     18       19, 8         9       13     14       14, 9        10       17     16       20]\n"
     ]
    }
   ],
   "source": [
    "print(newData.head())\n",
    "print(newData.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ae0c5-f402-4861-a6e5-e26d97836020",
   "metadata": {},
   "source": [
    "## Shape() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f5aeca4-776b-483c-b080-758d018adfb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add27aa3-bcff-4d17-9c97-f5937ee2282f",
   "metadata": {},
   "source": [
    "## Pandas Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e4da37-87e7-423a-9c3f-0ba6f53891e3",
   "metadata": {},
   "source": [
    "## Drop Rows With Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9ab1b9ae-ebb1-4402-bdfc-2b910ae1ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  4.0  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "Cleaned Data:\n",
      "      A    B    C\n",
      "1  2.0  2.0  2.0\n",
      "4  5.0  5.0  5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define a dictionary with sample data which includes some missing values\n",
    "data = {\n",
    "    'A': [1, 2, 3, None, 5],  \n",
    "    'B': [None, 2, 3, 4, 5],  \n",
    "    'C': [1, 2, None, None, 5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\\n\",df)\n",
    "print()\n",
    "\n",
    "# use dropna() to remove rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "print(\"Cleaned Data:\\n\",df_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34894b97-cab1-4ead-a3a2-ca04a270d910",
   "metadata": {},
   "source": [
    "## Fill Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea50f585-ce6b-45f5-afec-7963ec5a5504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  4.0  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "Data after filling NaN with 0:\n",
      "      A    B    C\n",
      "0  1.0  0.0  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  3.0  3.0  0.0\n",
      "3  0.0  4.0  0.0\n",
      "4  5.0  5.0  5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define a dictionary with sample data which includes some missing values\n",
    "data = {\n",
    "    'A': [1, 2, 3, None, 5],  \n",
    "    'B': [None, 2, 3, 4, 5],  \n",
    "    'C': [1, 2, None, None, 5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "\n",
    "# filling NaN values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "print(\"\\nData after filling NaN with 0:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf693c9-c763-415b-ba00-178295bb25d6",
   "metadata": {},
   "source": [
    "## Use Aggregate Functions to Fill Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "435ee212-85b4-430c-8983-c4d466b42361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      A    B    C\n",
      "0  1.0  NaN  1.0\n",
      "1  2.0  2.0  2.0\n",
      "2  3.0  3.0  NaN\n",
      "3  NaN  4.0  NaN\n",
      "4  5.0  5.0  5.0\n",
      "\n",
      "Data after filling NaN with mean:\n",
      "       A    B         C\n",
      "0  1.00  3.5  1.000000\n",
      "1  2.00  2.0  2.000000\n",
      "2  3.00  3.0  2.666667\n",
      "3  2.75  4.0  2.666667\n",
      "4  5.00  5.0  5.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# define a dictionary with sample data which includes some missing values\n",
    "data = {\n",
    "    'A': [1, 2, 3, None, 5],  \n",
    "    'B': [None, 2, 3, 4, 5],  \n",
    "    'C': [1, 2, None, None, 5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "\n",
    "# filling NaN values with the mean of each column\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "print(\"\\nData after filling NaN with mean:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca0396-9b2f-4faf-a370-c95341164379",
   "metadata": {},
   "source": [
    "## Handle Duplicates Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fb2601e9-259c-4012-bd4a-3b85924e88e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  A  B\n",
      " 1  5\n",
      " 2  6\n",
      " 2  6\n",
      " 3  7\n",
      " 3  8\n",
      " 4  8\n",
      "\n",
      "Duplicate Rows:\n",
      "  A  B\n",
      " 2  6\n",
      "\n",
      "DataFrame after removing duplicates based on column 'A':\n",
      "  A  B\n",
      " 1  5\n",
      " 2  6\n",
      " 3  7\n",
      " 4  8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# sample data\n",
    "data = {\n",
    "    'A': [1, 2, 2, 3, 3, 4],\n",
    "    'B': [5, 6, 6, 7, 8, 8]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\\n\", df.to_string(index=False))\n",
    "\n",
    "# detect duplicates\n",
    "print(\"\\nDuplicate Rows:\\n\", df[df.duplicated()].to_string(index=False))\n",
    "\n",
    "# remove duplicates based on column 'A'\n",
    "df.drop_duplicates(subset=['A'], keep='first', inplace=True)\n",
    "\n",
    "print(\"\\nDataFrame after removing duplicates based on column 'A':\\n\", df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b1068-a3fe-495f-9bfe-693589cfaf5e",
   "metadata": {},
   "source": [
    "## Rename Column Names to Meaningful Names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bd3e210f-8642-468e-8feb-bf7052e23df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Age  Name  Salary\n",
      "  25  John   50000\n",
      "  30   Doe   60000\n",
      "  35 Smith   70000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# sample data\n",
    "data = {\n",
    "    'A': [25, 30, 35],\n",
    "    'B': ['John', 'Doe', 'Smith'],\n",
    "    'C': [50000, 60000, 70000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# rename columns\n",
    "df.rename(columns={'A': 'Age', 'B': 'Name', 'C': 'Salary'}, inplace=True)\n",
    "\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01632c2-c157-4123-ada5-8913e985abf7",
   "metadata": {},
   "source": [
    "## Pandas Handling Missing Values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7726ef6e-5571-49b9-8533-3e2bf7f1e8d9",
   "metadata": {},
   "source": [
    "## Remove Rows Containing Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f3ecb007-e4a0-43e1-b9ec-0ee52b77d35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C  D\n",
      "0  1.0  NaN  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  NaN  3.0  3.0  3\n",
      "3  4.0  4.0  NaN  4\n",
      "4  5.0  5.0  5.0  5\n",
      "\n",
      "     A    B    C  D\n",
      "1  2.0  2.0  2.0  2\n",
      "4  5.0  5.0  5.0  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a dataframe with missing values\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5],\n",
    "    'C': [1, 2, 3, np.nan, 5],\n",
    "    'D': [1, 2, 3, 4, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print()\n",
    "# remove rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bfaae3-1cee-4145-a6cc-421f963992df",
   "metadata": {},
   "source": [
    "## Replace Missing Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0f4778c6-3a05-4340-b086-c96c5408fa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C  D\n",
      "0  1.0  NaN  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  NaN  3.0  3.0  3\n",
      "3  4.0  4.0  NaN  4\n",
      "4  5.0  5.0  5.0  5\n",
      "\n",
      "     A    B    C  D\n",
      "0  1.0  0.0  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  0.0  3.0  3.0  3\n",
      "3  4.0  4.0  0.0  4\n",
      "4  5.0  5.0  5.0  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a dataframe with missing values\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5],\n",
    "    'C': [1, 2, 3, np.nan, 5],\n",
    "    'D': [1, 2, 3, 4, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print()\n",
    "# replace missing values with 0\n",
    "df.fillna(value=0, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d786f3-dac0-46ef-b717-5d8d0e8613dc",
   "metadata": {},
   "source": [
    "## Replace Missing Values With Mean, Median and Mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2ec8ead9-a35d-40cd-99b5-bdc70bc69fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C  D\n",
      "0  1.0  NaN  1.0  1\n",
      "1  2.0  2.0  2.0  2\n",
      "2  NaN  3.0  3.0  3\n",
      "3  4.0  4.0  NaN  4\n",
      "4  5.0  5.0  5.0  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a dataframe with missing values\n",
    "data = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5],\n",
    "    'C': [1, 2, 3, np.nan, 5],\n",
    "    'D': [1, 2, 3, 4, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# replace missing values with mean\n",
    "df['A'].fillna(value=df['A'].mean() )\n",
    "\n",
    "# replace missing values with median\n",
    "df['B'].fillna(value=df['B'].median() )\n",
    "\n",
    "# replace missing values with mode\n",
    "df['C'].fillna(value=df['C'].mode()[0] )\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5961c4-a2ae-46aa-9176-44abd1c3c998",
   "metadata": {},
   "source": [
    "## Replace Values Using Another DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f3992f87-17ab-46bb-979b-6dadf6c7f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A     B     C  D\n",
      "0   1.0  10.0   1.0  1\n",
      "1   2.0   2.0   2.0  2\n",
      "2  30.0   3.0   3.0  3\n",
      "3   4.0   4.0  40.0  4\n",
      "4   5.0   5.0   5.0  5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# create a dataframe with missing values\n",
    "data1 = {\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [np.nan, 2, 3, 4, 5],\n",
    "    'C': [1, 2, 3, np.nan, 5],\n",
    "    'D': [1, 2, 3, 4, 5]\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# create datframe to fill the missing values with\n",
    "data2 = {\n",
    "    'A': [10, 20, 30, 40, 50],\n",
    "    'B': [10, 20, 30, 40, 50],\n",
    "    'C': [10, 20, 30, 40, 50],\n",
    "    'D': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# replace missing values\n",
    "df1.fillna(df2, inplace=True)\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da782e-d547-428b-8a77-fcea1002c3e6",
   "metadata": {},
   "source": [
    "## Pandas Handling Wrong Format "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955f0be-e026-4a9c-9f57-cdf7ae259487",
   "metadata": {},
   "source": [
    "## Convert Data to Correct Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "99b2c6d9-f181-4481-9bb6-d5d2dcd4548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.560000000000002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "data = {\n",
    "    'Country': ['USA', 'Canada', 'Australia', 'Germany', 'Japan'],\n",
    "    'Date': ['2023-07-20', '2023-07-21', '2023-07-22', '2023-07-23', '2023-07-24'],\n",
    "    'Temperature': [25.5, '28.0', 30.2, 22.8, 26.3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# convert temperature column to float\n",
    "df['Temperature'] = df['Temperature'].astype(float)\n",
    "\n",
    "# calculate the mean temperature\n",
    "mean_temperature = df['Temperature'].mean()\n",
    "\n",
    "print(mean_temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e89ce6c-cf42-4ac9-a4bb-d86cbfeb8466",
   "metadata": {},
   "source": [
    "## Handling Mixed Date Formats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "39379ad2-5d65-4fe4-b42a-abde266d3fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date\n",
      "0 2022-12-01\n",
      "1 2022-02-01\n",
      "2 2022-03-23\n",
      "3 2022-02-03\n",
      "4 2023-04-03\n",
      "5 2023-09-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a sample dataframe with mixed date formats\n",
    "df = pd.DataFrame({'date': ['2022-12-01', '01/02/2022', '2022-03-23', '03/02/2022', '3 4 2023', '2023.9.30']})\n",
    "\n",
    "# convert the date column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'], format='mixed', dayfirst=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55da1b3-cd87-49d0-864d-74f7b72e7cf3",
   "metadata": {},
   "source": [
    "## Pandas Handling Wrong Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6084a4d5-c9d9-4f05-b7e3-fa1d74828b08",
   "metadata": {},
   "source": [
    "## Replace Individual Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6d90bc66-6cdd-4e68-b855-0304e590971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age Gender  Standard\n",
      "0     John    8      M         3\n",
      "1  Michael    9      M         4\n",
      "2      Tom    7      M        12\n",
      "3     Alex   80      M         3\n",
      "4     Ryan  100      M         5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "data = {\n",
    "    'Name': ['John', 'Michael', 'Tom', 'Alex', 'Ryan'],\n",
    "    'Age': [8, 9, 7, 80, 100],\n",
    "    'Gender': ['M', 'M', 'M', 'F', 'M'],\n",
    "    'Standard': [3, 4, 12, 3, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# replace F with M\n",
    "df.loc[3, 'Gender'] = 'M'\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10acfcd6-be60-426a-8844-61f665dd8452",
   "metadata": {},
   "source": [
    "## Replace Values Based on a Condition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cb53182c-d92a-41ad-953a-494475e66565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age Gender  Standard\n",
      "0     John    8      M         3\n",
      "1  Michael    9      M         4\n",
      "2      Tom    7      M        12\n",
      "3     Alex    8      M         3\n",
      "4     Ryan   10      M         5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "data = {\n",
    "    'Name': ['John', 'Michael', 'Tom', 'Alex', 'Ryan'],\n",
    "    'Age': [8, 9, 7, 80, 100],\n",
    "    'Gender': ['M', 'M', 'M', 'M', 'M'],\n",
    "    'Standard': [3, 4, 12, 3, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# replace values based on conditions\n",
    "for i  in df.index:\n",
    "    age_val = df.loc[i, 'Age']\n",
    "    if (age_val > 14) and (age_val%10 == 0):\n",
    "        df.loc[i, 'Age'] = age_val/10\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98079b2a-9a1e-428f-b5ff-3f0fda93db21",
   "metadata": {},
   "source": [
    "## Remove Wrong Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c78b30f4-4a59-4f64-9290-d349751bc46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age Gender  Standard\n",
      "0     John    8      M         3\n",
      "1  Michael    9      M         4\n",
      "3     Alex    8      M         3\n",
      "4     Ryan   10      M         5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "data = {\n",
    "    'Name': ['John', 'Michael', 'Tom', 'Alex', 'Ryan'],\n",
    "    'Age': [8, 9, 7, 8, 10],\n",
    "    'Gender': ['M', 'M', 'M', 'M', 'M'],\n",
    "    'Standard': [3, 4, 12, 3, 5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# remove mistaken values\n",
    "for i in df.index:\n",
    "    if df.loc[i,'Standard'] > 8:\n",
    "        df.drop(i, inplace=True)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ea417-e82c-4a11-bb6f-19f668b7a747",
   "metadata": {},
   "source": [
    "## Pandas Get Dummies "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b196e10-f87e-4717-8e50-56d936a6470c",
   "metadata": {},
   "source": [
    "## Using get_dummies() on Pandas Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ffae1ac2-590c-4f77-bc94-f758c0de57d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       A      B      C\n",
      "0   True  False  False\n",
      "1  False   True  False\n",
      "2   True  False  False\n",
      "3  False  False   True\n",
      "4  False   True  False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a Panda Series\n",
    "data = pd.Series(['A', 'B', 'A', 'C', 'B'])\n",
    "\n",
    "# using get_dummies on the Series\n",
    "dummies = pd.get_dummies(data)\n",
    "\n",
    "print(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a919d2f-9576-408a-814e-1cd1ec26eb12",
   "metadata": {},
   "source": [
    "## Use get_dummies() on a DataFrame Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6d14a98b-93fe-45a9-9aad-5e42d2f79c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color   Blue  Green    Red\n",
      "0    Red  False  False   True\n",
      "1  Green  False   True  False\n",
      "2   Blue   True  False  False\n",
      "3  Green  False   True  False\n",
      "4    Red  False  False   True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# sample data\n",
    "data = {'Color': ['Red', 'Green', 'Blue', 'Green', 'Red']}\n",
    "\n",
    "# creating a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# using get_dummies to convert the categorical column\n",
    "dummies = pd.get_dummies(df['Color'])\n",
    "\n",
    "# concatenating the dummies DataFrame with the original DataFrame\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264814c-13f2-4606-a9e7-71aa492d143e",
   "metadata": {},
   "source": [
    "## Pandas Categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4279fff-b05f-418e-8c70-da85cbcde671",
   "metadata": {},
   "source": [
    " ## Create Categorical Data Type in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ce0454b3-84aa-4cef-aaef-c43afdb1a995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red', 'blue', 'green', 'red', 'blue']\n",
      "Categories (3, object): ['blue', 'green', 'red']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = ['red', 'blue', 'green', 'red', 'blue']\n",
    "\n",
    "# create a categorical column\n",
    "categorical_data = pd.Categorical(data)\n",
    "\n",
    "print(categorical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f4c62e-57fb-4b5a-9e11-4a303365566b",
   "metadata": {},
   "source": [
    "## Convert Pandas Series to Categorical Series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d69d13fc-c192-4c3f-a2a8-96a0949815ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      red\n",
      "1     blue\n",
      "2    green\n",
      "3      red\n",
      "4     blue\n",
      "dtype: category\n",
      "Categories (3, object): ['blue', 'green', 'red']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a regular Series\n",
    "data = ['red', 'blue', 'green', 'red', 'blue']\n",
    "series1 = pd.Series(data)\n",
    "\n",
    "# convert the Series to a categorical Series using .astype()\n",
    "categorical_s = series1.astype('category')\n",
    "\n",
    "print(categorical_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abd15d-ebc5-4371-a0e8-3cf97c8be4bd",
   "metadata": {},
   "source": [
    "## Using the dtype parameter Inside Series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2d04aa8e-34b4-4141-b09c-4909d60954bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A\n",
      "1    B\n",
      "2    A\n",
      "3    C\n",
      "4    B\n",
      "dtype: category\n",
      "Categories (3, object): ['A', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a categorical Series\n",
    "data = ['A', 'B', 'A', 'C', 'B']\n",
    "cat_series = pd.Series(data, dtype=\"category\")\n",
    "\n",
    "print(cat_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69f42e-2096-4758-9a24-a8f0d88d5939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
